# Model Performans Değerlendirme Ölçütleri

## Giriş

Bir makine öğrenmesi modeli geliştirdiğimizde, temel sorumuz şudur: "Bu model ne kadar iyi çalışıyor?" Bu sorunun cevabını nesnel olarak verebilmek için performans ölçütlerine başvururuz. Bu ölçütler, modelimizin tahmin yeteneğini, hatalarını ve genel gücünü sayısal olarak ifade etmemizi sağlayan birer karne notu gibidir.

## Karışıklık Matrisi (Confusion Matrix)

Sınıflandırma problemlerinde, model performansını analiz etmeye genellikle **Karışıklık Matrisi (Confusion Matrix)** ile başlarız. Bu tablo, modelin tahminlerinin gerçek değerlerle karşılaştırmasını basit ve anlaşılır bir formatta sunar.

```
                      Tahmin Edilen
                 Pozitif (P)    Negatif (N)
              ┌──────────────┬──────────────┐
Gerçek    (P) │     TP       │      FN      │
              ├──────────────┼──────────────┤
          (N) │     FP       │      TN      │
              └──────────────┴──────────────┘
```

### Temel Tanımlar

*   **Gerçek Pozitif (True Positive - TP):** Modelin, pozitif bir durumu doğru bir şekilde pozitif olarak tahmin etmesi. (Örn: Hasta bir kişiye 'hasta' tanısı konulması.)
*   **Gerçek Negatif (True Negative - TN):** Modelin, negatif bir durumu doğru bir şekilde negatif olarak tahmin etmesi. (Örn: Sağlıklı bir kişiye 'sağlıklı' tanısı konulması.)
*   **Sahte Pozitif (False Positive - FP):** Modelin, negatif bir durumu hatalı bir şekilde pozitif olarak tahmin etmesi. Buna **Tip I Hata** da denir. (Örn: Sağlıklı bir kişiye 'hasta' tanısı konulması.)
*   **Sahte Negatif (False Negative - FN):** Modelin, pozitif bir durumu hatalı bir şekilde negatif olarak tahmin etmesi. Buna **Tip II Hata** da denir. (Örn: Hasta bir kişiye 'sağlıklı' tanısı konulması.)

### Örnek

1000 kişilik bir veri setinde modelimizin performansını değerlendirelim:
*   Gerçekte Pozitif (Hasta): 500 kişi
*   Gerçekte Negatif (Sağlıklı): 500 kişi

Modelimizin tahminleri sonucunda oluşan karışıklık matrisi:

```
              Tahmin
           P        N      Toplam
      ┌─────────┬─────────┬────────┐
  P   │   350   │   150   │   500  │
Gerçek├─────────┼─────────┼────────┤
  N   │   250   │   250   │   500  │
      └─────────┴─────────┴────────┘
Toplam   600       400      1000
```
Bu matris, aşağıda inceleyeceğimiz birçok performans ölçütünün temelini oluşturur.

## Sınıflandırma Performans Ölçütleri

Karışıklık matrisinden türetilen temel metrikler şunlardır:

*   **Doğruluk (Accuracy):** En temel ölçüttür ve "Tüm tahminlerin yüzde kaçı doğru?" sorusunu yanıtlar.
    ```
    Accuracy = (TP + TN) / (Toplam Veri Sayısı)
    ```
    **Örneğimizde:** `(350 + 250) / 1000 = 0,60` (%60)
    **Not:** Doğruluk, özellikle sınıfların dengesiz dağıldığı (örneğin, 990 sağlıklı kişiye karşılık 10 hasta) veri setlerinde yanıltıcı olabilir. Herkese "sağlıklı" diyen bir model %99 doğruluk oranına sahip olabilir ama asıl aranan hasta kişileri bulamaz. Bu nedenle daha spesifik metriklere ihtiyaç duyarız.

*   **Kesinlik (Precision):** Bu metrik, "'Pozitif' olarak tahmin ettiklerimizin ne kadarı gerçekten pozitifti?" sorusuna odaklanır.
    ```
    Precision = TP / (TP + FP)
    ```
    **Örneğimizde:** `350 / (350 + 250) = 350 / 600 ≈ 0,58`
    **Yorumlama:** Yüksek kesinlik, modelin pozitif etiketlemesi yaptığında buna güvenebileceğimiz anlamına gelir. Sahte pozitiflerin maliyetinin yüksek olduğu durumlarda (örn: bir e-postanın yanlışlıkla spam olarak işaretlenmesi) kritik bir metriktir.

*   **Duyarlılık (Recall / Sensitivity):** Duyarlılık, "Gerçekte pozitif olan vakaların yüzde kaçını tespit edebildik?" sorusunu cevaplar.
    ```
    Recall = TP / (TP + FN)
    ```
    **Örneğimizde:** `350 / (350 + 150) = 350 / 500 = 0,70`
    **Yorumlama:** Yüksek duyarlılık, modelin pozitif vakaları atlamadığını gösterir. Sahte negatiflerin maliyetinin yüksek olduğu durumlarda (örn: bir hastalığın teşhis edilememesi) hayati önem taşır.

*   **F1-Skoru (F1-Score):** Kesinlik ve duyarlılık arasında bir denge kurar. Bu iki metriğin harmonik ortalamasıdır ve her ikisinin de önemli olduğu durumlarda kullanılır.
    ```
    F1-Score = (2 × Precision × Recall) / (Precision + Recall)
    ```
    **Örneğimizde:** `(2 × 0,58 × 0,70) / (0,58 + 0,70) ≈ 0,63`
    **Yorumlama:** F1-Skoru, modelin hem sahte pozitiflerden kaçınma (Precision)

## ROC Eğrisinin Kökeni ve Oluşturulması

ROC eğrisinin mantığını anlamak için kökenine inmek faydalı olacaktır. Bu kavram, II. Dünya Savaşı sırasında radar operatörlerinin sinyalleri yorumlama performansını ölçmek için geliştirilmiştir. Operatörün görevi, radar ekranındaki sinyallerin bir düşman uçağı mı (pozitif durum) yoksa zararsız bir kuş sürüsü veya atmosferik bir gürültü mü (negatif durum) olduğuna karar vermektir.

Operatörün karar verme "hassasiyeti" kritik bir rol oynar.
*   **Çok hassas olursa:** En zayıf sinyali bile düşman olarak işaretler. Bu durumda hiçbir düşmanı kaçırmaz (yüksek **Gerçek Pozitif Oranı**), ancak çok sayıda yanlış alarm verir (yüksek **Sahte Pozitif Oranı**).
*   **Az hassas olursa:** Sadece çok güçlü ve net sinyalleri düşman olarak işaretler. Bu durumda yanlış alarm sayısı çok az olur (düşük **Sahte Pozitif Oranı**), ancak bazı gerçek düşmanları gözden kaçırabilir (düşük **Gerçek Pozitif Oranı**).

ROC eğrisi, operatörün (veya makine öğrenmesi modelimizin) bu hassasiyet seviyesinin tüm olası değerleri için doğru tespitler ile yanlış alarmlar arasındaki dengeyi görselleştiren bir grafiktir.

### ROC Eğrisi Nasıl Çizilir?

Çoğu sınıflandırma modeli, bir örneğin belirli bir sınıfa ait olup olmadığına dair sadece "evet" veya "hayır" şeklinde kesin bir cevap vermez. Bunun yerine, o sınıfa ait olma olasılığını gösteren bir skor (örneğin 0 ile 1 arasında bir değer) üretir. Biz de bu skoru bir **eşik (threshold)** değeriyle karşılaştırarak nihai kararı veririz. Genellikle bu eşik 0.5'tir; skor 0.5'ten büyükse "pozitif", küçükse "negatif" olarak sınıflandırırız.

ROC eğrisi, bu eşik değerini sistematik olarak değiştirerek modelin davranışını analiz etmemizi sağlar. Adım adım oluşturulması şöyledir:

1.  Model, test setindeki her bir veri noktası için bir olasılık skoru hesaplar.
2.  Eşik değeri 1.0'dan başlatılır. Bu eşikte, hiçbir örnek pozitif olarak sınıflandırılmaz çünkü hiçbir skor 1.0'dan büyük olamaz.
3.  Bu duruma ait Karışıklık Matrisi (Confusion Matrix) oluşturulur ve iki oran hesaplanır:
    *   **Gerçek Pozitif Oranı (True Positive Rate - TPR):** Gerçekte pozitif olanların ne kadarının doğru tahmin edildiğini gösterir. Bu, **Duyarlılık (Recall)** ile aynıdır. `TPR = TP / (TP + FN)`
    *   **Sahte Pozitif Oranı (False Positive Rate - FPR):** Gerçekte negatif olanların ne kadarının yanlışlıkla pozitif olarak etiketlendiğini gösterir. `FPR = FP / (FP + TN)`
4.  Eşik değeri kademeli olarak (örneğin 0.99, 0.98, ...) 0'a doğru düşürülür. Her yeni eşik değeri için yeni bir karışıklık matrisi oluşur ve yeni bir (FPR, TPR) çifti hesaplanır.
5.  Hesaplanan tüm bu (FPR, TPR) noktaları bir grafiğe yerleştirilir. X ekseni FPR'yi, Y ekseni ise TPR'yi temsil eder. Bu noktaların birleştirilmesiyle ROC eğrisi elde edilir.

Bu eğri, modelin farklı "hassasiyet" seviyelerindeki performansını tek bir görselde özetler ve bize modelin sınıfları ne kadar iyi ayırt edebildiğine dair bütüncül bir bakış açısı sunar.

## Pratik Uygulamalar

Bu metrikleri hesaplamak için hem görsel arayüzlü araçlar hem de programlama kütüphaneleri yaygın olarak kullanılır.

### Weka ile Değerlendirme

**Weka**, kod yazmadan makine öğrenmesi modelleri oluşturup değerlendirmenizi sağlayan popüler bir görsel araçtır.

1.  **Veri Setini Yükleme:** Weka "Explorer" arayüzünde, "Preprocess" sekmesinden `iris.arff` gibi hazır bir veri setini yükleyin.
2.  **Sınıflandırıcı Seçimi:** "Classify" sekmesinde, "Choose" butonu ile `trees` altından `J48` (bir karar ağacı algoritması) seçin.
3.  **Değerlendirme:** Test seçeneği olarak "Cross-validation" (Çapraz Doğrulama) kullanarak "Start" butonuna basın.
4.  **Sonuçları Yorumlama:** "Classifier output" panelinde şu sonuçları göreceksiniz:
    *   **`Correctly Classified Instances`**: **Doğruluk (Accuracy)**.
    *   **`Detailed Accuracy By Class`** tablosu: Her sınıf için `TP Rate` (**Recall**), `Precision`, `F-Measure` (**F1-Skoru**) ve `ROC Area` (**AUC**) değerlerini içerir.
    *   **`Confusion Matrix`**: Panelin en altında, öğrendiğimiz **Karışıklık Matrisi**'ni bulabilirsiniz.

Örnek bir Weka Karışıklık Matrisi çıktısı:
```
=== Confusion Matrix ===

  a  b  c   <-- classified as
 50  0  0 |  a = Iris-setosa
  0 47  3 |  b = Iris-versicolor
  0  1 49 |  c = Iris-virginica
```
Bu matris, `Iris-versicolor` sınıfından 3 örneğin hatalı bir şekilde `Iris-virginica` olarak sınıflandırıldığını açıkça gösterir.

### Python (Scikit-learn) ile Değerlendirme

Python'da makine öğrenmesi için en yaygın kütüphane olan **Scikit-learn**, tüm bu metrikleri hesaplamak için hazır fonksiyonlar sunar. Aşağıdaki örnek, bir modelin performansını nasıl değerlendireceğinizi gösterir. Bu kodu doğrudan bir Google Colab not defterinde çalıştırabilirsiniz.
Python'da makine öğrenmesi için en yaygın kütüphane olan **Scikit-learn**, bu metrikleri hesaplamak için bize son derece pratik fonksiyonlar sunar. Şimdi, öğrendiğimiz teorik bilgileri bir örnek üzerinde nasıl uygulayacağımızı görelim.

Aşağıdaki kod, sentetik bir veri seti oluşturur, bu veri üzerinde basit bir Lojistik Regresyon modeli eğitir ve ardından performansını, az önce öğrendiğimiz metrikler ve görsellerle kapsamlı bir şekilde analiz eder. Bu kodu doğrudan bir Google Colab not defterinde çalıştırarak sonuçları kendiniz de gözlemleyebilirsiniz.

```python
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Veri Seti Oluşturma
# Sınıfları dengesiz bir veri seti oluşturalım.
# Örneklerin %90'ı 0. sınıfa, %10'u ise 1. sınıfa ait olacak.
X, y = make_classification(
    n_samples=1000,
    n_features=2,
    n_informative=2,
    n_redundant=0,
    weights=[0.9, 0.1],
    flip_y=0,
    random_state=42
)

# 2. Veriyi Eğitim ve Test Olarak Ayırma
# stratify=y parametresi, eğitim ve test setlerindeki sınıf oranlarının
# orijinal veri setindekiyle aynı kalmasını sağlar. Bu, dengesiz veri setlerinde önemlidir.
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 3. Model Eğitimi
model = LogisticRegression()
model.fit(X_train, y_train)

# 4. Tahmin Yapma
# predict() -> Nihai sınıf etiketini (0 veya 1) tahmin eder.
y_pred = model.predict(X_test)
# predict_proba() -> Her sınıf için olasılıkları verir. ROC eğrisi için gereklidir.
# [:, 1] ile sadece pozitif sınıfın (sınıf 1) olasılıklarını alıyoruz.
y_pred_proba = model.predict_proba(X_test)[:, 1]

# 5. Performans Metriklerini Raporlama
print("--- Sınıflandırma Raporu ---")
# classification_report, temel metrikleri düzenli bir formatta sunar.
print(classification_report(y_test, y_pred, target_names=['Negatif Sınıf (0)', 'Pozitif Sınıf (1)']))
print("-" * 30)

# 6. Karışıklık Matrisini Görselleştirme
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Tahmin Negatif', 'Tahmin Pozitif'],
            yticklabels=['Gerçek Negatif', 'Gerçek Pozitif'])
plt.title('Karışıklık Matrisi')
plt.show()

# 7. ROC Eğrisini Çizme
# roc_curve fonksiyonu, farklı eşik değerleri için FPR ve TPR'yi hesaplar.
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
# auc fonksiyonu, bu eğrinin altında kalan alanı hesaplar.
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Eğrisi (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Rastgele Tahmin')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Sahte Pozitif Oranı (FPR)')
plt.ylabel('Gerçek Pozitif Oranı (TPR)')
plt.title('Alıcı İşletim Karakteristiği (ROC) Eğrisi')
plt.legend(loc="lower right")
plt.show()
```

### Kodun Adım Adım Açıklaması

Gençler, bu kod parçasının ne yaptığını daha iyi anlayalım:

1.  **Veri Seti Oluşturma:** Gerçek dünya problemlerini daha iyi yansıtması için `make_classification` ile yapay bir veri seti oluşturduk. `weights=[0.9, 0.1]` parametresiyle, sınıflardan birinin diğerinden çok daha fazla örneğe sahip olduğu **dengesiz (imbalanced)** bir durum yarattık. Bu, `Accuracy` metriğinin neden tek başına yeterli olmayabileceğini göstermek için önemlidir.
2.  **Veriyi Ayırma:** Modelimizi eğitmek ve test etmek için veriyi ikiye ayırdık. `stratify=y` parametresi, bu dengesiz sınıf dağılımının hem eğitim hem de test setlerinde korunmasını garanti eder. Böylece modelimizi adil bir şekilde değerlendirebiliriz.
3.  **Model Eğitimi:** Basit ama güçlü bir sınıflandırma algoritması olan `LogisticRegression` modelini eğitim verileriyle (`X_train`, `y_train`) eğittik.
4.  **Tahmin Yapma:** Eğitilen modelimizi daha önce hiç görmediği test verileri (`X_test`) üzerinde çalıştırdık. Burada iki tür tahmin yaptık: `predict()` ile modelin kesin kararını (0 veya 1) ve `predict_proba()` ile modelin bir örneğin pozitif sınıfa ait olma olasılığını aldık. Bu olasılık değeri, ROC eğrisini çizmek için kritik öneme sahiptir.
5.  **Sınıflandırma Raporu:** `classification_report` fonksiyonu, her sınıf için Kesinlik (Precision), Duyarlılık (Recall) ve F1-Skoru değerlerini tek bir tabloda özetleyerek bize hızlı bir genel bakış sunar.
6.  **Karışıklık Matrisi:** Teoride gördüğümüz karışıklık matrisini `seaborn` kütüphanesiyle görselleştirdik. Bu ısı haritası, modelin ne tür hatalar yaptığını (FP veya FN) bir bakışta anlamamızı sağlar.
7.  **ROC Eğrisi ve AUC:** Modelin pozitif sınıf için ürettiği olasılıkları (`y_pred_proba`) kullanarak, farklı karar eşikleri için Sahte Pozitif Oranı (FPR) ve Gerçek Pozitif Oranı (TPR) değerlerini hesapladık. Bu noktaları birleştirerek ROC eğrisini çizdik. Eğrinin altında kalan alan (AUC), modelin genel ayırt etme gücünün sayısal bir ölçüsüdür. AUC değeri 1'e ne kadar yakınsa, model o kadar iyidir.

## Son Sözler

Gençler, unutmayın ki tek bir "en iyi" performans ölçütü yoktur; probleme ve hedefe "en uygun" ölçüt vardır. Bir modelin başarısını değerlendirirken, problemin bağlamını göz önünde bulundurarak birden fazla metriği birlikte analiz etmek esastır.

*   Bir hastalığın teşhisinde, hiçbir vakayı atlamamak öncelikli olduğu için **Duyarlılık (Recall)** kritik olabilir.
*   Bir spam filtresinde, önemli bir e-postayı yanlışlıkla engellememek için **Kesinlik (Precision)** daha önemli olabilir.
*   Sınıfların dengesiz olduğu durumlarda **Doğruluk (Accuracy)** yerine **F1-Skoru** veya **AUC** gibi metriklere odaklanmak daha sağlıklı sonuçlar verir.

Bu metrikler, geliştirdiğiniz modelleri anlama ve iyileştirme sürecinizde size yol gösterecek temel araçlardır.
