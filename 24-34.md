# Model Performans Değerlendirme Ölçütleri

## Giriş

Bir makine öğrenmesi modeli geliştirdiğimizde, temel sorumuz şudur: "Bu model ne kadar iyi çalışıyor?" Bu sorunun cevabını nesnel olarak verebilmek için performans ölçütlerine başvururuz. Bu ölçütler, modelimizin tahmin yeteneğini, hatalarını ve genel gücünü sayısal olarak ifade etmemizi sağlayan birer karne notu gibidir.

## Karışıklık Matrisi (Confusion Matrix)

Sınıflandırma problemlerinde, model performansını analiz etmeye genellikle **Karışıklık Matrisi (Confusion Matrix)** ile başlarız. Bu tablo, modelin tahminlerinin gerçek değerlerle karşılaştırmasını basit ve anlaşılır bir formatta sunar.

```
                      Tahmin Edilen
                 Pozitif (P)    Negatif (N)
              ┌──────────────┬──────────────┐
Gerçek    (P) │     TP       │      FN      │
              ├──────────────┼──────────────┤
          (N) │     FP       │      TN      │
              └──────────────┴──────────────┘
```

### Temel Tanımlar

*   **Gerçek Pozitif (True Positive - TP):** Modelin, pozitif bir durumu doğru bir şekilde pozitif olarak tahmin etmesi. (Örn: Hasta bir kişiye 'hasta' tanısı konulması.)
*   **Gerçek Negatif (True Negative - TN):** Modelin, negatif bir durumu doğru bir şekilde negatif olarak tahmin etmesi. (Örn: Sağlıklı bir kişiye 'sağlıklı' tanısı konulması.)
*   **Yanlış Pozitif (False Positive - FP):** Modelin, negatif bir durumu hatalı bir şekilde pozitif olarak tahmin etmesi. Buna **Tip I Hata** da denir. (Örn: Sağlıklı bir kişiye 'hasta' tanısı konulması.)
*   **Yanlış Negatif (False Negative - FN):** Modelin, pozitif bir durumu hatalı bir şekilde negatif olarak tahmin etmesi. Buna **Tip II Hata** da denir. (Örn: Hasta bir kişiye 'sağlıklı' tanısı konulması.)

### Örnek

1000 kişilik bir veri setinde modelimizin performansını değerlendirelim:
*   Gerçekte Pozitif (Hasta): 500 kişi
*   Gerçekte Negatif (Sağlıklı): 500 kişi

Modelimizin tahminleri sonucunda oluşan karışıklık matrisi:

```
              Tahmin
           P        N      Toplam
      ┌─────────┬─────────┬────────┐
  P   │   350   │   150   │   500  │
Gerçek├─────────┼─────────┼────────┤
  N   │   250   │   250   │   500  │
      └─────────┴─────────┴────────┘
Toplam   600       400      1000
```
Bu matris, aşağıda inceleyeceğimiz birçok performans ölçütünün temelini oluşturur.

## Sınıflandırma Performans Ölçütleri

Karışıklık matrisinden türetilen temel metrikler şunlardır:

*   **Doğruluk (Accuracy):** En temel ölçüttür ve "Tüm tahminlerin yüzde kaçı doğru?" sorusunu yanıtlar.
    ```
    Accuracy = (TP + TN) / (Toplam Veri Sayısı)
    ```
    **Örneğimizde:** `(350 + 250) / 1000 = 0,60` (%60)
    **Not:** Doğruluk, özellikle sınıfların dengesiz dağıldığı (örneğin, 990 sağlıklı kişiye karşılık 10 hasta) veri setlerinde yanıltıcı olabilir. Herkese "sağlıklı" diyen bir model %99 doğruluk oranına sahip olabilir ama asıl aranan hasta kişileri bulamaz. Bu nedenle daha spesifik metriklere ihtiyaç duyarız.

*   **Kesinlik (Precision):** Bu metrik, "'Pozitif' olarak tahmin ettiklerimizin ne kadarı gerçekten pozitifti?" sorusuna odaklanır.
    ```
    Precision = TP / (TP + FP)
    ```
    **Örneğimizde:** `350 / (350 + 250) = 350 / 600 ≈ 0,58`
    **Yorumlama:** Yüksek kesinlik, modelin pozitif etiketlemesi yaptığında buna güvenebileceğimiz anlamına gelir. Yanlış pozitiflerin maliyetinin yüksek olduğu durumlarda (örn: bir e-postanın yanlışlıkla spam olarak işaretlenmesi) kritik bir metriktir.

*   **Duyarlılık (Recall / Sensitivity):** Duyarlılık, "Gerçekte pozitif olan vakaların yüzde kaçını tespit edebildik?" sorusunu cevaplar.
    ```
    Recall = TP / (TP + FN)
    ```
    **Örneğimizde:** `350 / (350 + 150) = 350 / 500 = 0,70`
    **Yorumlama:** Yüksek duyarlılık, modelin pozitif vakaları atlamadığını gösterir. Yanlış negatiflerin maliyetinin yüksek olduğu durumlarda (örn: bir hastalığın teşhis edilememesi) hayati önem taşır.

*   **F1-Skoru (F1-Score):** Kesinlik ve duyarlılık arasında bir denge kurar. Bu iki metriğin harmonik ortalamasıdır ve her ikisinin de önemli olduğu durumlarda kullanılır.
    ```
    F1-Score = (2 × Precision × Recall) / (Precision + Recall)
    ```
    **Örneğimizde:** `(2 × 0,58 × 0,70) / (0,58 + 0,70) ≈ 0,63`
    **Yorumlama:** F1-Skoru, modelin hem yanlış pozitiflerden kaçınma (Precision)

## ROC Eğrisinin Kökeni ve Oluşturulması

ROC eğrisinin mantığını anlamak için kökenine inmek faydalı olacaktır. Bu kavram, II. Dünya Savaşı sırasında radar operatörlerinin sinyalleri yorumlama performansını ölçmek için geliştirilmiştir. Operatörün görevi, radar ekranındaki sinyallerin bir düşman uçağı mı (pozitif durum) yoksa zararsız bir kuş sürüsü veya atmosferik bir gürültü mü (negatif durum) olduğuna karar vermektir.

Operatörün karar verme "hassasiyeti" kritik bir rol oynar.
*   **Çok hassas olursa:** En zayıf sinyali bile düşman olarak işaretler. Bu durumda hiçbir düşmanı kaçırmaz (yüksek **Doğru Pozitif Oranı**), ancak çok sayıda yanlış alarm verir (yüksek **Yanlış Pozitif Oranı**).
*   **Az hassas olursa:** Sadece çok güçlü ve net sinyalleri düşman olarak işaretler. Bu durumda yanlış alarm sayısı çok az olur (düşük **Yanlış Pozitif Oranı**), ancak bazı gerçek düşmanları gözden kaçırabilir (düşük **Doğru Pozitif Oranı**).

ROC eğrisi, operatörün (veya makine öğrenmesi modelimizin) bu hassasiyet seviyesinin tüm olası değerleri için doğru tespitler ile yanlış alarmlar arasındaki dengeyi görselleştiren bir grafiktir.

### ROC Eğrisi Nasıl Çizilir?

Çoğu sınıflandırma modeli, bir örneğin belirli bir sınıfa ait olup olmadığına dair sadece "evet" veya "hayır" şeklinde kesin bir cevap vermez. Bunun yerine, o sınıfa ait olma olasılığını gösteren bir skor (örneğin 0 ile 1 arasında bir değer) üretir. Biz de bu skoru bir **eşik (threshold)** değeriyle karşılaştırarak nihai kararı veririz. Genellikle bu eşik 0.5'tir; skor 0.5'ten büyükse "pozitif", küçükse "negatif" olarak sınıflandırırız.

ROC eğrisi, bu eşik değerini sistematik olarak değiştirerek modelin davranışını analiz etmemizi sağlar. Adım adım oluşturulması şöyledir:

1.  Model, test setindeki her bir veri noktası için bir olasılık skoru hesaplar.
2.  Eşik değeri 1.0'dan başlatılır. Bu eşikte, hiçbir örnek pozitif olarak sınıflandırılmaz çünkü hiçbir skor 1.0'dan büyük olamaz.
3.  Bu duruma ait Karışıklık Matrisi (Confusion Matrix) oluşturulur ve iki oran hesaplanır:
    *   **Doğru Pozitif Oranı (True Positive Rate - TPR):** Gerçekte pozitif olanların ne kadarının doğru tahmin edildiğini gösterir. Bu, **Duyarlılık (Recall)** ile aynıdır. `TPR = TP / (TP + FN)`
    *   **Yanlış Pozitif Oranı (False Positive Rate - FPR):** Gerçekte negatif olanların ne kadarının yanlışlıkla pozitif olarak etiketlendiğini gösterir. `FPR = FP / (FP + TN)`
4.  Eşik değeri kademeli olarak (örneğin 0.99, 0.98, ...) 0'a doğru düşürülür. Her yeni eşik değeri için yeni bir karışıklık matrisi oluşur ve yeni bir (FPR, TPR) çifti hesaplanır.
5.  Hesaplanan tüm bu (FPR, TPR) noktaları bir grafiğe yerleştirilir. X ekseni FPR'yi, Y ekseni ise TPR'yi temsil eder. Bu noktaların birleştirilmesiyle ROC eğrisi elde edilir.

Bu eğri, modelin farklı "hassasiyet" seviyelerindeki performansını tek bir görselde özetler ve bize modelin sınıfları ne kadar iyi ayırt edebildiğine dair bütüncül bir bakış açısı sunar.

Bu metrikleri, **Weka** gibi görsel bir araçla kolayca hesaplayabiliriz.

1.  **Veri Setini Yükleme:** Weka "Explorer" arayüzünde, "Preprocess" sekmesinden `iris.arff` gibi hazır bir veri setini yükleyin.
2.  **Sınıflandırıcı Seçimi:** "Classify" sekmesinde, "Choose" butonu ile `trees` altından `J48` (bir karar ağacı algoritması) seçin.
3.  **Değerlendirme:** Test seçeneği olarak "Cross-validation" (Çapraz Doğrulama) kullanarak "Start" butonuna basın.
4.  **Sonuçları Yorumlama:** "Classifier output" panelinde şu sonuçları göreceksiniz:
    *   **`Correctly Classified Instances`**: **Doğruluk (Accuracy)**.
    *   **`Detailed Accuracy By Class`** tablosu: Her sınıf için `TP Rate` (**Recall**), `Precision`, `F-Measure` (**F1-Skoru**) ve `ROC Area` (**AUC**) değerlerini içerir.
    *   **`Confusion Matrix`**: Panelin en altında, öğrendiğimiz **Karışıklık Matrisi**'ni bulabilirsiniz.

Örnek bir Weka Karışıklık Matrisi çıktısı:
```
=== Confusion Matrix ===

  a  b  c   <-- classified as
 50  0  0 |  a = Iris-setosa
  0 47  3 |  b = Iris-versicolor
  0  1 49 |  c = Iris-virginica
```
Bu matris, `Iris-versicolor` sınıfından 3 örneğin hatalı bir şekilde `Iris-virginica` olarak sınıflandırıldığını açıkça gösterir.

## Son Sözler

Gençler, unutmayın ki tek bir "en iyi" performans ölçütü yoktur; probleme ve hedefe "en uygun" ölçüt vardır. Bir modelin başarısını değerlendirirken, problemin bağlamını göz önünde bulundurarak birden fazla metriği birlikte analiz etmek esastır.

*   Bir hastalığın teşhisinde, hiçbir vakayı atlamamak öncelikli olduğu için **Duyarlılık (Recall)** kritik olabilir.
*   Bir spam filtresinde, önemli bir e-postayı yanlışlıkla engellememek için **Kesinlik (Precision)** daha önemli olabilir.
*   Sınıfların dengesiz olduğu durumlarda **Doğruluk (Accuracy)** yerine **F1-Skoru** veya **AUC** gibi metriklere odaklanmak daha sağlıklı sonuçlar verir.

Bu metrikler, geliştirdiğiniz modelleri anlama ve iyileştirme sürecinizde size yol gösterecek temel araçlardır.
